{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single TLU network\n",
    "*Hebb's Rule: Cells that fire together wire together*\n",
    "\n",
    "*TLU - Linear threshold Unit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "model = Perceptron()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2,\n",
       "       1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(iris.data)\n",
    "#(iris['target']==0).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classifier using fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test)= fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale dataset and create a validation dataset\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding class names to identify the target 'y' variable\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using sequential API\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[28,28]))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1a62ff47f0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a62ff4940>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a63019240>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a63019160>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.02550611, -0.02086007, -0.05837977, ..., -0.00574809,\n",
       "         -0.00418356,  0.03361554],\n",
       "        [ 0.05586438,  0.02066121, -0.06989749, ...,  0.0365214 ,\n",
       "          0.00113191,  0.0644293 ],\n",
       "        [-0.02672585,  0.02523105,  0.00174233, ...,  0.01229561,\n",
       "          0.02180742,  0.00823364],\n",
       "        ...,\n",
       "        [ 0.03111353,  0.06490807, -0.01821039, ..., -0.0658093 ,\n",
       "         -0.02130804,  0.0014559 ],\n",
       "        [ 0.02620674,  0.07198261,  0.04219073, ..., -0.0661746 ,\n",
       "         -0.04744989,  0.01624369],\n",
       "        [-0.05424973, -0.00645354,  0.04177215, ..., -0.01345095,\n",
       "          0.06528772, -0.03700545]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.08737515, -0.07779714, -0.10396115, ..., -0.10181727,\n",
       "         -0.07022524,  0.09445217],\n",
       "        [-0.09266106, -0.11920319,  0.04814447, ...,  0.03731779,\n",
       "          0.0684103 ,  0.10390701],\n",
       "        [-0.09348164, -0.07925005,  0.06060713, ..., -0.11933134,\n",
       "         -0.05175792, -0.11947107],\n",
       "        ...,\n",
       "        [ 0.04862871, -0.01774271,  0.07991307, ..., -0.09092359,\n",
       "         -0.00261827,  0.11086335],\n",
       "        [-0.11890873, -0.04257695, -0.05130915, ...,  0.08171145,\n",
       "         -0.10951971, -0.09131917],\n",
       "        [-0.11098827, -0.05092966,  0.07266819, ..., -0.01557985,\n",
       "         -0.03307912, -0.0974821 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[-0.02349043,  0.19328198,  0.06331283,  0.03201708,  0.16116762,\n",
       "          0.17197064, -0.07534066,  0.23319548,  0.10528508,  0.20359474],\n",
       "        [-0.21854295, -0.21480069, -0.08496489, -0.12182013,  0.14811945,\n",
       "         -0.18507777,  0.07012498,  0.04538611, -0.2258642 ,  0.08415192],\n",
       "        [ 0.09286892, -0.15694347, -0.04516871,  0.07166827,  0.1857124 ,\n",
       "          0.12691352,  0.1125865 , -0.05819882,  0.03595263,  0.0324586 ],\n",
       "        [ 0.18095669, -0.1169028 , -0.15733905,  0.10934606,  0.02892143,\n",
       "          0.06825772, -0.2277793 ,  0.20723498,  0.13333741, -0.09828466],\n",
       "        [-0.05756883, -0.06203569,  0.10579523, -0.14312914,  0.15744027,\n",
       "         -0.14548123,  0.00982264,  0.206312  ,  0.02892175, -0.10383505],\n",
       "        [-0.19146211, -0.21026456, -0.05788033, -0.192512  ,  0.05265686,\n",
       "          0.0678691 ,  0.1512276 , -0.20647559,  0.02253458, -0.03510514],\n",
       "        [ 0.21899292, -0.13273118,  0.19092399,  0.00079203,  0.17384398,\n",
       "          0.15890151, -0.0946306 ,  0.09715387,  0.1969597 , -0.21785025],\n",
       "        [ 0.10050845,  0.11490586,  0.15263331,  0.01118518,  0.16459554,\n",
       "         -0.05157448,  0.20743042,  0.00530115,  0.01373667,  0.13247061],\n",
       "        [-0.18210483, -0.21374345, -0.04371239,  0.07232478, -0.14481086,\n",
       "          0.16600141,  0.0629991 , -0.12097476, -0.09106998, -0.01788758],\n",
       "        [-0.04329777,  0.02538425,  0.11269793, -0.08999775, -0.01679982,\n",
       "         -0.04721431,  0.12840542, -0.04923733, -0.11223994,  0.05313125],\n",
       "        [ 0.14706483,  0.17035681,  0.22146812,  0.21788824, -0.1810031 ,\n",
       "         -0.17963982, -0.12554613, -0.14439702,  0.19528922,  0.08986038],\n",
       "        [-0.09855099, -0.21030354, -0.09343082, -0.15415516, -0.06907113,\n",
       "          0.02802333, -0.04156409, -0.22617653, -0.15590762, -0.03272721],\n",
       "        [-0.14209098,  0.15405917, -0.01305395,  0.00168529,  0.0492112 ,\n",
       "         -0.15281335, -0.1473227 ,  0.22474265, -0.12087771, -0.10657808],\n",
       "        [ 0.10474545, -0.1227424 , -0.15487215,  0.10319254,  0.08880758,\n",
       "          0.15483701, -0.17958196, -0.0591374 ,  0.23040238,  0.00066379],\n",
       "        [-0.19465479,  0.1862418 , -0.22693482,  0.20260236, -0.1029135 ,\n",
       "         -0.02043311,  0.16306356,  0.19504562,  0.04855779, -0.09333688],\n",
       "        [ 0.21854433,  0.14627999, -0.01333086,  0.19750512, -0.159457  ,\n",
       "         -0.01075554,  0.07550412,  0.19895956, -0.13023148,  0.04897267],\n",
       "        [ 0.03606117, -0.18608613,  0.18802488, -0.18892828, -0.1119495 ,\n",
       "         -0.10657251, -0.05727834, -0.01377237, -0.15652959,  0.18011758],\n",
       "        [ 0.0651038 , -0.02885666, -0.2247147 ,  0.19143856,  0.09819373,\n",
       "          0.09791765, -0.10766189,  0.06672978,  0.12496749,  0.06227806],\n",
       "        [-0.03673525,  0.20802513, -0.23197214, -0.17248672, -0.13161765,\n",
       "         -0.05487201, -0.08585508, -0.11220024,  0.16652533,  0.01589805],\n",
       "        [ 0.13295352,  0.2165649 , -0.15241498, -0.13619442, -0.0175761 ,\n",
       "         -0.00566515,  0.21142581,  0.14469421,  0.07854   , -0.06452231],\n",
       "        [-0.06291474,  0.05982515,  0.01948863,  0.01216665, -0.17081675,\n",
       "          0.01319532,  0.08784229,  0.10477012, -0.12993419, -0.15408257],\n",
       "        [ 0.16907287,  0.02947006,  0.22996017, -0.22911902,  0.18640006,\n",
       "          0.21681684,  0.12683305, -0.15337823,  0.00114055, -0.04944284],\n",
       "        [-0.21638581,  0.22667295, -0.1744977 , -0.06306744,  0.0368475 ,\n",
       "         -0.06371413, -0.04504125,  0.1555185 ,  0.06991705,  0.06124988],\n",
       "        [ 0.01865059,  0.22976065, -0.11815154, -0.18829857, -0.08313945,\n",
       "         -0.22927637, -0.0547719 , -0.00785714,  0.08392847,  0.06011313],\n",
       "        [ 0.17033488,  0.06070164,  0.16671601, -0.03886388,  0.07740068,\n",
       "         -0.12310974,  0.12489471,  0.03843316, -0.03307496,  0.20605552],\n",
       "        [-0.03463952,  0.20130327, -0.06932704, -0.17862356,  0.07392865,\n",
       "         -0.20717752, -0.11230832, -0.15996209, -0.22886589,  0.04086858],\n",
       "        [ 0.1888951 , -0.0862173 ,  0.14649853,  0.01155636,  0.02329385,\n",
       "          0.21764734, -0.02356081,  0.01633455, -0.2164828 , -0.19924788],\n",
       "        [-0.11421316, -0.08652344, -0.2273487 ,  0.08581606, -0.0708176 ,\n",
       "         -0.05291365, -0.23085693,  0.02576071, -0.05011411,  0.10038489],\n",
       "        [-0.14913955, -0.02499235, -0.03964399, -0.04234616, -0.16177867,\n",
       "          0.10964879,  0.23233774,  0.19735065,  0.16766956,  0.06627274],\n",
       "        [-0.05034663,  0.19223788, -0.06169842,  0.07173115, -0.05566493,\n",
       "         -0.01967494, -0.03901784,  0.14519602,  0.05322888, -0.13482602],\n",
       "        [ 0.07597971, -0.18935814, -0.21302213, -0.1807641 , -0.17063187,\n",
       "          0.1829586 , -0.03604417, -0.05240466, -0.08204138, -0.04573222],\n",
       "        [-0.16443679, -0.15588735,  0.22414288, -0.1240819 ,  0.1643987 ,\n",
       "         -0.00190373, -0.01216136, -0.0102393 ,  0.06854698, -0.18387803],\n",
       "        [-0.03308725,  0.03694034,  0.21555325, -0.13727835, -0.05289033,\n",
       "         -0.07339895, -0.1818847 ,  0.18791893, -0.12679803,  0.23030111],\n",
       "        [ 0.06799656,  0.08717522,  0.08860034, -0.0831939 , -0.1362423 ,\n",
       "         -0.19136071,  0.15896782,  0.20851317, -0.15676829, -0.21119563],\n",
       "        [ 0.05971   ,  0.22932288,  0.0166423 ,  0.09103814,  0.01643154,\n",
       "          0.10812896, -0.11842165, -0.16089672,  0.16651365, -0.05841793],\n",
       "        [ 0.09852684,  0.12173393,  0.05615437,  0.19037953,  0.1823129 ,\n",
       "          0.23351577,  0.04458961,  0.07501623, -0.03195173,  0.10364762],\n",
       "        [-0.11774105, -0.17900664, -0.10186489,  0.2031979 ,  0.08207926,\n",
       "         -0.2222562 , -0.19803382, -0.07544957, -0.14605954, -0.12241766],\n",
       "        [-0.1529775 , -0.22003947,  0.0569748 ,  0.0147987 ,  0.1379042 ,\n",
       "          0.13516197,  0.06533751,  0.06914163,  0.04841045, -0.01365326],\n",
       "        [-0.07351053,  0.15553877, -0.04069428, -0.17385629, -0.11532453,\n",
       "         -0.10522404,  0.12249404,  0.13016015,  0.04160497,  0.03837717],\n",
       "        [ 0.22777021, -0.05739215,  0.09214398, -0.07704321, -0.08929972,\n",
       "         -0.04004028,  0.04409748, -0.15041693, -0.05172016, -0.17910063],\n",
       "        [ 0.15021208,  0.06493765, -0.1559903 , -0.11449854, -0.07194857,\n",
       "         -0.13103755,  0.13037258,  0.18790549, -0.06854521,  0.05636173],\n",
       "        [-0.04599899, -0.06382795, -0.14746046, -0.18284501, -0.18915407,\n",
       "         -0.01189286, -0.16621467, -0.1743061 ,  0.0370445 ,  0.08455744],\n",
       "        [ 0.00372601, -0.18763366, -0.00903489, -0.1207503 , -0.20750427,\n",
       "          0.05806541, -0.21556148, -0.06118062, -0.18120226,  0.1556055 ],\n",
       "        [ 0.15109864, -0.13168028, -0.08590692, -0.18117882,  0.09483269,\n",
       "          0.18781435, -0.13661209,  0.01884729,  0.2243714 ,  0.21046954],\n",
       "        [-0.01774538,  0.18568215,  0.07805714,  0.20721376, -0.12986192,\n",
       "          0.03457114, -0.22898734, -0.16160366,  0.09034109,  0.098829  ],\n",
       "        [-0.01828332, -0.21531297, -0.06718498, -0.177144  , -0.00549231,\n",
       "         -0.01255186,  0.16593292,  0.20204264,  0.20111871,  0.1004338 ],\n",
       "        [ 0.18186423,  0.16273296, -0.0433186 ,  0.21109429, -0.16586417,\n",
       "         -0.20067997, -0.19566253, -0.04373817, -0.2052333 ,  0.165524  ],\n",
       "        [-0.18893602,  0.19587597,  0.17065287,  0.0459325 ,  0.21753448,\n",
       "          0.21244255,  0.08408305,  0.15582693,  0.00562622,  0.1988498 ],\n",
       "        [ 0.22034839, -0.15737118, -0.18897232,  0.14234862,  0.06341556,\n",
       "          0.16685915,  0.20796883,  0.08088452,  0.05698082,  0.10676423],\n",
       "        [-0.16420305,  0.00279148,  0.15859386,  0.10234025,  0.0897949 ,\n",
       "          0.0192185 ,  0.1372222 ,  0.14223114, -0.18812355,  0.14068154],\n",
       "        [ 0.18128711,  0.06633049,  0.21014625, -0.15636483,  0.13434443,\n",
       "          0.05845636,  0.08711514,  0.10986045,  0.18230706, -0.03569861],\n",
       "        [ 0.13204706, -0.15974638,  0.08290657, -0.08885771, -0.03590146,\n",
       "          0.18566746,  0.10038611,  0.16846403, -0.10534416, -0.06765735],\n",
       "        [-0.1360752 , -0.16350126,  0.19621512,  0.03676671,  0.0504052 ,\n",
       "         -0.12551978, -0.1592984 ,  0.05519837, -0.15640141, -0.207067  ],\n",
       "        [-0.18040444, -0.07931338,  0.05581015,  0.00794056,  0.17627525,\n",
       "          0.1483432 , -0.17714407, -0.2321667 ,  0.02638826, -0.01323992],\n",
       "        [-0.13369048,  0.13850358,  0.10990271, -0.06315991, -0.21965817,\n",
       "         -0.10129498, -0.0552448 , -0.19771472, -0.03870291,  0.21345735],\n",
       "        [ 0.1970967 ,  0.21748537, -0.1691936 , -0.04423302,  0.04821929,\n",
       "         -0.09206219, -0.05699614, -0.07395728, -0.07524471,  0.09073126],\n",
       "        [ 0.15425953, -0.12327038, -0.10668504, -0.06347002,  0.09914845,\n",
       "         -0.16355217, -0.11319807, -0.2009663 , -0.17360555,  0.02392671],\n",
       "        [-0.16104144, -0.17558567, -0.19262348,  0.04224572, -0.02843064,\n",
       "          0.10594529,  0.07201001,  0.21505442,  0.21921581,  0.03033197],\n",
       "        [ 0.20730743, -0.11764761, -0.04214948,  0.05879602, -0.10640518,\n",
       "         -0.06687021, -0.07662219,  0.1637119 ,  0.23091772, -0.12354328],\n",
       "        [-0.03510174, -0.10228406,  0.01892975, -0.00852156,  0.22672862,\n",
       "         -0.0813944 ,  0.19074118, -0.1172884 , -0.08697787, -0.23340741],\n",
       "        [-0.1787382 ,  0.05201554,  0.16612169, -0.0470324 ,  0.12319577,\n",
       "         -0.0078817 ,  0.08835262, -0.06367777,  0.09073105,  0.01680961],\n",
       "        [ 0.03364798,  0.10309348, -0.0883721 ,  0.0982312 , -0.2037625 ,\n",
       "          0.02984348, -0.01922648, -0.03172499, -0.17992106,  0.22123319],\n",
       "        [-0.19712833, -0.0464934 , -0.21566083,  0.22165906, -0.08544464,\n",
       "          0.08737433, -0.22377978,  0.22290167,  0.06630069,  0.11588508],\n",
       "        [-0.07224932, -0.0198303 ,  0.07439989,  0.0951716 ,  0.04011101,\n",
       "          0.11667401,  0.21539545,  0.10182217, -0.1554052 ,  0.1986405 ],\n",
       "        [ 0.20150253, -0.22126745,  0.00029083, -0.00777267, -0.13014579,\n",
       "          0.09256071,  0.23129603, -0.21702872, -0.01427858, -0.02367479],\n",
       "        [-0.14825684,  0.18422729,  0.11827087,  0.02791294, -0.05825233,\n",
       "         -0.1952507 , -0.08447443,  0.17989284,  0.15110889,  0.09035063],\n",
       "        [ 0.1908266 , -0.2244737 , -0.12085549, -0.03802665, -0.1387885 ,\n",
       "          0.05664384,  0.04803324,  0.16782269, -0.18274595,  0.13739794],\n",
       "        [-0.15428591,  0.00509067, -0.10541332,  0.11601806,  0.11257893,\n",
       "         -0.18666962,  0.2251415 , -0.09579542, -0.16153462,  0.20510918],\n",
       "        [-0.12630375, -0.0171959 ,  0.01302639,  0.02237812, -0.17791794,\n",
       "         -0.20689549, -0.01226915, -0.18944696,  0.03266463,  0.01802245],\n",
       "        [ 0.19719747, -0.02916431, -0.13720462,  0.21142483, -0.03402556,\n",
       "         -0.19163229, -0.07024553,  0.11438155,  0.14779228, -0.04384775],\n",
       "        [ 0.04247957,  0.22674489,  0.08723757, -0.02235077, -0.22514807,\n",
       "          0.15537032,  0.17466274, -0.06780022, -0.01950355,  0.20987606],\n",
       "        [-0.18081394,  0.19565558, -0.18441075,  0.20853129,  0.17799133,\n",
       "          0.1051977 ,  0.2279791 , -0.03039795,  0.05692816, -0.07940514],\n",
       "        [-0.18600845,  0.11362141, -0.17409137,  0.18150991, -0.16385275,\n",
       "          0.2207472 , -0.117985  , -0.05751571,  0.14515   , -0.05364399],\n",
       "        [-0.12430112, -0.16140388,  0.22510892,  0.15033123,  0.03139484,\n",
       "         -0.17340831,  0.01728466,  0.09598085, -0.17219494, -0.14078271],\n",
       "        [ 0.18562156,  0.1477969 ,  0.18954551, -0.07368672,  0.18674904,\n",
       "         -0.1941297 ,  0.03634569, -0.2028663 ,  0.09191751, -0.2118699 ],\n",
       "        [ 0.04042751,  0.05182663,  0.22786582, -0.09821388, -0.00548507,\n",
       "         -0.03972307, -0.16783433, -0.09062664, -0.14178707,  0.06509271],\n",
       "        [ 0.17788073,  0.10668087,  0.11257076,  0.11704457, -0.08938558,\n",
       "          0.00606211, -0.21025388,  0.19258505, -0.17206275,  0.11406115],\n",
       "        [ 0.22554258,  0.20999867,  0.06134978,  0.17575705, -0.21903552,\n",
       "         -0.156811  , -0.123006  ,  0.07027867, -0.14916785, -0.00997147],\n",
       "        [-0.21923882, -0.00900282, -0.06785201, -0.16099873, -0.20095706,\n",
       "          0.18033427, -0.14613877, -0.03070877,  0.12019104, -0.1406257 ],\n",
       "        [-0.14552844, -0.15573394,  0.20797578,  0.05622321, -0.07136224,\n",
       "          0.01305467, -0.1460944 ,  0.2161364 ,  0.0074653 , -0.14278847],\n",
       "        [ 0.18083248,  0.19127414, -0.00979184, -0.02932289, -0.17479375,\n",
       "         -0.13097747, -0.1041678 , -0.22230865, -0.13464957,  0.08232152],\n",
       "        [-0.2271184 , -0.10807255,  0.12764755, -0.21684134, -0.19760424,\n",
       "         -0.11882056,  0.07619098, -0.19387518,  0.16419518,  0.06352219],\n",
       "        [ 0.1159175 , -0.0282446 , -0.19744438,  0.17150563,  0.09721532,\n",
       "          0.11743411,  0.16026795, -0.20449495, -0.08879529, -0.09110601],\n",
       "        [ 0.00258946, -0.01802312, -0.01442307,  0.11576894, -0.0721996 ,\n",
       "         -0.21208355,  0.18217441, -0.16431624, -0.16136584,  0.23199591],\n",
       "        [ 0.09483552, -0.10135545,  0.17903459,  0.0559586 , -0.09182164,\n",
       "          0.1795913 ,  0.1803731 , -0.09919429, -0.03331472,  0.00607057],\n",
       "        [-0.06306587,  0.02771115,  0.01131414, -0.11739849, -0.03869867,\n",
       "          0.02410838,  0.03746346, -0.20336494,  0.15272564,  0.03417864],\n",
       "        [ 0.16611719, -0.05242844,  0.22271952, -0.09266412,  0.14509094,\n",
       "         -0.05280463,  0.10932139,  0.13700092, -0.06662244,  0.02639198],\n",
       "        [-0.23065257, -0.08682774, -0.1003527 ,  0.19715804,  0.17255071,\n",
       "          0.1538116 ,  0.21314296,  0.16002095, -0.00198826,  0.06225854],\n",
       "        [-0.1923433 , -0.08533351,  0.16090924, -0.19630566,  0.06044406,\n",
       "          0.19592792,  0.12688991,  0.04898301,  0.10597721,  0.04410741],\n",
       "        [-0.14344701, -0.13096471,  0.16771239, -0.02749595, -0.17940338,\n",
       "         -0.21811113, -0.13104261,  0.10924137,  0.15104786, -0.13339214],\n",
       "        [-0.00424646, -0.21032916,  0.15048185,  0.19384944,  0.07807338,\n",
       "          0.05659974,  0.0858728 ,  0.10812226,  0.21506506,  0.0303542 ],\n",
       "        [-0.09062012,  0.06849048,  0.09077665,  0.15549979, -0.15993859,\n",
       "         -0.1730097 , -0.21431346,  0.17457741, -0.10044008,  0.11123431],\n",
       "        [-0.1207738 , -0.13981223, -0.18445458, -0.01983073, -0.15550914,\n",
       "         -0.22700103,  0.12676072, -0.07146749, -0.17619595,  0.21582323],\n",
       "        [ 0.14533788, -0.04849519,  0.14995971,  0.14044517, -0.07619873,\n",
       "          0.19721138,  0.15722752, -0.09927242,  0.17665762, -0.03183284],\n",
       "        [ 0.16580743, -0.2241273 ,  0.08591521, -0.20900953,  0.06866637,\n",
       "         -0.2220838 , -0.14175421, -0.1456697 , -0.1552195 , -0.16990326],\n",
       "        [ 0.1529949 , -0.21598455,  0.1277358 , -0.05346057,  0.10984215,\n",
       "          0.06118977, -0.17332646, -0.15975088, -0.23005338,  0.00380485],\n",
       "        [ 0.07136291,  0.22238082, -0.20052335,  0.03918779, -0.01081601,\n",
       "          0.00580513,  0.18474764, -0.02871968, -0.0957448 , -0.07755503],\n",
       "        [-0.0090346 ,  0.06422713, -0.01769876,  0.18254349,  0.16022992,\n",
       "          0.12260437, -0.00118938, -0.15064189, -0.22308348, -0.00580369],\n",
       "        [-0.05003586, -0.19158429,  0.1482679 , -0.00923267, -0.09809919,\n",
       "          0.01681396, -0.18902382, -0.16227926, -0.01155715,  0.22053516],\n",
       "        [-0.21011105, -0.11469148, -0.01966231,  0.04852998, -0.14121091,\n",
       "          0.09034866, -0.15134226, -0.04271618, -0.1666847 ,  0.04651412]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 10s 185us/sample - loss: 0.7101 - acc: 0.7662 - val_loss: 0.5195 - val_acc: 0.8204\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 10s 184us/sample - loss: 0.4813 - acc: 0.8338 - val_loss: 0.4583 - val_acc: 0.8434\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 10s 178us/sample - loss: 0.4390 - acc: 0.8452 - val_loss: 0.4032 - val_acc: 0.8668\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 10s 190us/sample - loss: 0.4123 - acc: 0.8549 - val_loss: 0.4046 - val_acc: 0.8610\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.3943 - acc: 0.8610 - val_loss: 0.3879 - val_acc: 0.8654\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 11s 208us/sample - loss: 0.3780 - acc: 0.8661 - val_loss: 0.3849 - val_acc: 0.8640\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.3660 - acc: 0.8709 - val_loss: 0.3706 - val_acc: 0.8716\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 10s 187us/sample - loss: 0.3549 - acc: 0.8745 - val_loss: 0.3548 - val_acc: 0.8764\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 10s 186us/sample - loss: 0.3444 - acc: 0.8778 - val_loss: 0.3630 - val_acc: 0.8738\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 10s 185us/sample - loss: 0.3364 - acc: 0.8799 - val_loss: 0.3791 - val_acc: 0.8656\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 11s 191us/sample - loss: 0.3277 - acc: 0.8829 - val_loss: 0.3475 - val_acc: 0.8762\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.3203 - acc: 0.8851 - val_loss: 0.3397 - val_acc: 0.8778\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 11s 193us/sample - loss: 0.3120 - acc: 0.8882 - val_loss: 0.3457 - val_acc: 0.8764\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 10s 190us/sample - loss: 0.3053 - acc: 0.8903 - val_loss: 0.3576 - val_acc: 0.8732\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 10s 187us/sample - loss: 0.2991 - acc: 0.8926 - val_loss: 0.3366 - val_acc: 0.8770\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 10s 188us/sample - loss: 0.2929 - acc: 0.8947 - val_loss: 0.3300 - val_acc: 0.8800\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 10s 189us/sample - loss: 0.2867 - acc: 0.8976 - val_loss: 0.3186 - val_acc: 0.8846\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 10s 188us/sample - loss: 0.2820 - acc: 0.8985 - val_loss: 0.3235 - val_acc: 0.8834\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 14s 253us/sample - loss: 0.2765 - acc: 0.8992 - val_loss: 0.3069 - val_acc: 0.8918\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 13s 230us/sample - loss: 0.2707 - acc: 0.9017 - val_loss: 0.3531 - val_acc: 0.8720\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 12s 217us/sample - loss: 0.2660 - acc: 0.9045 - val_loss: 0.3053 - val_acc: 0.8916\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 10s 189us/sample - loss: 0.2613 - acc: 0.9065 - val_loss: 0.3175 - val_acc: 0.8868\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 11s 191us/sample - loss: 0.2574 - acc: 0.9063 - val_loss: 0.3149 - val_acc: 0.8910\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 10s 191us/sample - loss: 0.2530 - acc: 0.9085 - val_loss: 0.3092 - val_acc: 0.8890\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 10s 186us/sample - loss: 0.2489 - acc: 0.9103 - val_loss: 0.3261 - val_acc: 0.8860\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 10s 184us/sample - loss: 0.2454 - acc: 0.9118 - val_loss: 0.2966 - val_acc: 0.8948\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 12s 223us/sample - loss: 0.2411 - acc: 0.9128 - val_loss: 0.3013 - val_acc: 0.8926\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 10s 187us/sample - loss: 0.2371 - acc: 0.9146 - val_loss: 0.3063 - val_acc: 0.8922\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.2323 - acc: 0.9161 - val_loss: 0.3142 - val_acc: 0.8908\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 10s 184us/sample - loss: 0.2287 - acc: 0.9180 - val_loss: 0.3187 - val_acc: 0.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a47a29e10>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 109us/sample - loss: 66.0953 - acc: 0.8442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[66.09526018251155, 0.8442]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalauate the model on test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 0, 1, 4, 4, 5, 7, 4, 5, 5, 3, 4, 1, 2, 2, 8, 0, 2, 5,\n",
       "       7, 5, 1, 4, 4, 0, 9, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "# model.predict_proba(X_test[:30])\n",
    "model.predict_classes(X_test[:30])\n",
    "# Check predictions\n",
    "#y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression MLP using sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /Users/Nirmal.Venkatachalam@ey.com/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Train, test & validation data \n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "# Standardize the data for training\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 149us/sample - loss: 0.7380 - val_loss: 0.4417\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 80us/sample - loss: 0.4361 - val_loss: 0.4073\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 88us/sample - loss: 0.4078 - val_loss: 1.2185\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.4003 - val_loss: 1.4687\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.3943 - val_loss: 0.8485\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 92us/sample - loss: 0.4758 - val_loss: 0.6704\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 82us/sample - loss: 0.3894 - val_loss: 0.3782\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3810 - val_loss: 0.4037\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 0.3770 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 78us/sample - loss: 0.3866 - val_loss: 1.2562\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 80us/sample - loss: 0.3796 - val_loss: 0.3481\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.4060 - val_loss: 1.4919\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.3702 - val_loss: 0.5367\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 93us/sample - loss: 0.3673 - val_loss: 0.6629\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 92us/sample - loss: 0.3679 - val_loss: 0.3713\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 88us/sample - loss: 0.3659 - val_loss: 0.8253\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.3629 - val_loss: 0.7092\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 85us/sample - loss: 0.3640 - val_loss: 0.4225\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 0.3590 - val_loss: 3.2471\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3583 - val_loss: 0.3776\n",
      "5160/5160 [==============================] - 0s 33us/sample - loss: 0.3651\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = keras.models.Sequential([keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "                                keras.layers.Dense(1)])\n",
    "# Compile the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep neural network using Functional API\n",
    "Paper link [here](https://arxiv.org/pdf/1606.07792.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full inputs passed both as wide and deep inputs\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 197us/sample - loss: 0.7236 - val_loss: 21.2803\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 112us/sample - loss: 0.4873 - val_loss: 0.4761\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 122us/sample - loss: 0.4247 - val_loss: 6.1241\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 103us/sample - loss: 0.3945 - val_loss: 1.5358\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 0.3845 - val_loss: 1.3352\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 2s 148us/sample - loss: 0.3752 - val_loss: 1.1851\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 127us/sample - loss: 0.3695 - val_loss: 0.5659\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 124us/sample - loss: 0.3620 - val_loss: 0.7717\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 111us/sample - loss: 0.3874 - val_loss: 12.7274\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 107us/sample - loss: 0.4270 - val_loss: 0.7755\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 123us/sample - loss: 0.3789 - val_loss: 0.6620\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 0.3566 - val_loss: 1.6481\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 111us/sample - loss: 0.3489 - val_loss: 2.7382\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 0.3543 - val_loss: 2.6479\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 108us/sample - loss: 0.3465 - val_loss: 0.3204\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 111us/sample - loss: 0.3384 - val_loss: 0.7484\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 0.3772 - val_loss: 0.9216\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 127us/sample - loss: 0.3441 - val_loss: 0.3372\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 115us/sample - loss: 0.3488 - val_loss: 3.0544\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 116us/sample - loss: 0.3369 - val_loss: 1.5565\n",
      "5160/5160 [==============================] - 0s 59us/sample - loss: 0.3379\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the available features and passing them differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 165us/sample - loss: 2.1278 - val_loss: 2.0854\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 91us/sample - loss: 0.7899 - val_loss: 1.8267\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 111us/sample - loss: 0.6560 - val_loss: 1.6852\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.5955 - val_loss: 1.5793\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 89us/sample - loss: 0.5576 - val_loss: 1.5067\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 82us/sample - loss: 0.5303 - val_loss: 1.4352\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.5093 - val_loss: 1.4013\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.4925 - val_loss: 1.4129\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 108us/sample - loss: 0.4790 - val_loss: 1.4526\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 122us/sample - loss: 0.4684 - val_loss: 1.3614\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 118us/sample - loss: 0.4590 - val_loss: 1.3376\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 118us/sample - loss: 0.4513 - val_loss: 1.3579\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.4447 - val_loss: 1.4126\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 108us/sample - loss: 0.4392 - val_loss: 1.3598\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 0.4340 - val_loss: 1.3258\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.4300 - val_loss: 1.2398\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 100us/sample - loss: 0.4263 - val_loss: 1.2540\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 0.4230 - val_loss: 1.2094\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 105us/sample - loss: 0.4202 - val_loss: 1.1354\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 2s 137us/sample - loss: 0.4177 - val_loss: 1.1467\n",
      "5160/5160 [==============================] - 0s 64us/sample - loss: 0.4279\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having an auxiliary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 210us/sample - loss: 0.8986 - main_output_loss: 0.7850 - aux_output_loss: 1.9194 - val_loss: 3.7208 - val_main_output_loss: 3.9812 - val_aux_output_loss: 1.3603\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 107us/sample - loss: 1.9947 - main_output_loss: 2.0351 - aux_output_loss: 1.6278 - val_loss: 2.0101 - val_main_output_loss: 1.9513 - val_aux_output_loss: 2.5320\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 112us/sample - loss: 0.5899 - main_output_loss: 0.5058 - aux_output_loss: 1.3466 - val_loss: 0.7157 - val_main_output_loss: 0.6552 - val_aux_output_loss: 1.2599\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 2s 136us/sample - loss: 0.4987 - main_output_loss: 0.4376 - aux_output_loss: 1.0486 - val_loss: 0.7690 - val_main_output_loss: 0.7399 - val_aux_output_loss: 1.0309\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 107us/sample - loss: 0.4639 - main_output_loss: 0.4139 - aux_output_loss: 0.9130 - val_loss: 0.8577 - val_main_output_loss: 0.8568 - val_aux_output_loss: 0.8663\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 112us/sample - loss: 0.4458 - main_output_loss: 0.4055 - aux_output_loss: 0.8106 - val_loss: 0.6935 - val_main_output_loss: 0.6861 - val_aux_output_loss: 0.7581\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 117us/sample - loss: 0.4377 - main_output_loss: 0.4049 - aux_output_loss: 0.7356 - val_loss: 0.6158 - val_main_output_loss: 0.6040 - val_aux_output_loss: 0.7203\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.4414 - main_output_loss: 0.4145 - aux_output_loss: 0.6818 - val_loss: 0.6457 - val_main_output_loss: 0.6357 - val_aux_output_loss: 0.7331\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 124us/sample - loss: 0.4134 - main_output_loss: 0.3873 - aux_output_loss: 0.6478 - val_loss: 0.5148 - val_main_output_loss: 0.4833 - val_aux_output_loss: 0.7966\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 122us/sample - loss: 0.4062 - main_output_loss: 0.3819 - aux_output_loss: 0.6253 - val_loss: 0.6522 - val_main_output_loss: 0.6298 - val_aux_output_loss: 0.8536\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 0.4013 - main_output_loss: 0.3787 - aux_output_loss: 0.6078 - val_loss: 0.5760 - val_main_output_loss: 0.5385 - val_aux_output_loss: 0.9110\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 121us/sample - loss: 0.3966 - main_output_loss: 0.3746 - aux_output_loss: 0.5940 - val_loss: 0.4471 - val_main_output_loss: 0.3915 - val_aux_output_loss: 0.9459\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 125us/sample - loss: 0.3926 - main_output_loss: 0.3716 - aux_output_loss: 0.5813 - val_loss: 0.4992 - val_main_output_loss: 0.4478 - val_aux_output_loss: 0.9605\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 119us/sample - loss: 0.3893 - main_output_loss: 0.3692 - aux_output_loss: 0.5701 - val_loss: 0.6563 - val_main_output_loss: 0.5916 - val_aux_output_loss: 1.2370\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 2s 133us/sample - loss: 0.3851 - main_output_loss: 0.3656 - aux_output_loss: 0.5608 - val_loss: 0.6485 - val_main_output_loss: 0.6049 - val_aux_output_loss: 1.0402\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 125us/sample - loss: 0.3843 - main_output_loss: 0.3654 - aux_output_loss: 0.5533 - val_loss: 0.9495 - val_main_output_loss: 0.9575 - val_aux_output_loss: 0.8755\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 2s 132us/sample - loss: 0.3791 - main_output_loss: 0.3608 - aux_output_loss: 0.5445 - val_loss: 0.9167 - val_main_output_loss: 0.9322 - val_aux_output_loss: 0.7739\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 2s 133us/sample - loss: 0.3762 - main_output_loss: 0.3582 - aux_output_loss: 0.5378 - val_loss: 0.5637 - val_main_output_loss: 0.5395 - val_aux_output_loss: 0.7809\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 129us/sample - loss: 0.3712 - main_output_loss: 0.3535 - aux_output_loss: 0.5312 - val_loss: 0.5592 - val_main_output_loss: 0.5318 - val_aux_output_loss: 0.8048\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 126us/sample - loss: 0.3682 - main_output_loss: 0.3507 - aux_output_loss: 0.5249 - val_loss: 0.5169 - val_main_output_loss: 0.4862 - val_aux_output_loss: 0.7939\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 57us/sample - loss: 0.3777 - main_output_loss: 0.3594 - aux_output_loss: 0.5297\n"
     ]
    }
   ],
   "source": [
    "# return losses\n",
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for both the outputs\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5713506],\n",
       "       [3.119655 ],\n",
       "       [2.9617078]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7912395],\n",
       "       [2.9572034],\n",
       "       [3.2304718]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.734, 2.57 , 2.754, ..., 2.196, 2.267, 1.402])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
